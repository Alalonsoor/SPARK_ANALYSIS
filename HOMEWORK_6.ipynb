{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "HOMEWORK 6 - Movie Rating Analysis using Apache Spark (Pipeline)"
      ],
      "metadata": {
        "id": "utsWCrAk_r_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing Space"
      ],
      "metadata": {
        "id": "Y0nuDnlk9zmC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "q6lhYyXl_l8S",
        "outputId": "0f3d9b68-0f93-4c39-a1c4-2c2cf0eac7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,765 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,017 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,553 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,984 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,295 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,740 kB]\n",
            "Fetched 21.8 MB in 3s (8,103 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "movies.csv  ratings.csv\t\t       spark-3.1.1-bin-hadoop3.2.tgz\n",
            "output\t    sample_data\n",
            "output.csv  spark-3.1.1-bin-hadoop3.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78e442dec590>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a41cf1da449f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>MovieRatingsAnalysis</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Install and configure Spark environment\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "\n",
        "!ls\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload datasets ratings and movies from the 32M dataset"
      ],
      "metadata": {
        "id": "AadqKrL799_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"MovieRatingsAnalysis\").getOrCreate()\n",
        "\n",
        "movies = spark.read.csv(\"movies.csv\", header=True, inferSchema=True)\n",
        "ratings = spark.read.csv(\"ratings.csv\", header=True, inferSchema=True)\n",
        "\n",
        "start_time_join = time.time()\n",
        "data = ratings.join(movies, on=\"movieId\")\n",
        "spark_time_join = time.time() - start_time_join\n",
        "\n",
        "print(f\"Spark join execution time: {spark_time_join:.2f} seconds\")\n",
        "\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MfuUfEE88xY",
        "outputId": "1f7fcf54-1a6b-4464-c20a-6c41cb8b2106"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark join execution time: 0.02 seconds\n",
            "+-------+------+------+---------+--------------------+--------------------+\n",
            "|movieId|userId|rating|timestamp|               title|              genres|\n",
            "+-------+------+------+---------+--------------------+--------------------+\n",
            "|     17|     1|   4.0|944249077|Sense and Sensibi...|       Drama|Romance|\n",
            "|     25|     1|   1.0|944250228|Leaving Las Vegas...|       Drama|Romance|\n",
            "|     29|     1|   2.0|943230976|City of Lost Chil...|Adventure|Drama|F...|\n",
            "|     30|     1|   5.0|944249077|Shanghai Triad (Y...|         Crime|Drama|\n",
            "|     32|     1|   5.0|943228858|Twelve Monkeys (a...|Mystery|Sci-Fi|Th...|\n",
            "+-------+------+------+---------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we would do is calculate average rating and number of ratings for each movie, and then classify it between different categories"
      ],
      "metadata": {
        "id": "qfAZ26v1_DX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import avg, count, when\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "movie_stats = data.groupBy(\"movieId\", \"title\") \\\n",
        "    .agg(avg(\"rating\").alias(\"avg_rating\"), count(\"rating\").alias(\"num_ratings\"))\n",
        "\n",
        "movie_stats = movie_stats.withColumn(\n",
        "    \"category\",\n",
        "    when(movie_stats.avg_rating >= 8, \"Excellent\")\n",
        "    .when(movie_stats.avg_rating >= 7, \"Good\")\n",
        "    .when(movie_stats.avg_rating >= 5, \"Regular\")\n",
        "    .otherwise(\"Bad\")\n",
        ")\n",
        "\n",
        "spark_time = time.time() - start_time\n",
        "\n",
        "movie_stats.show(10)\n",
        "print(f\"Spark execution time: {spark_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_yn7onX9VMz",
        "outputId": "d523933b-a5f0-4251-a775-34a27e8bbcdd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+------------------+-----------+--------+\n",
            "|movieId|               title|        avg_rating|num_ratings|category|\n",
            "+-------+--------------------+------------------+-----------+--------+\n",
            "|    442|Demolition Man (1...|3.0941247002398082|      20850|     Bad|\n",
            "| 183837|       The Favourite|3.8472875509564126|       3189|     Bad|\n",
            "|   2657|Rocky Horror Pict...| 3.363947776628749|      15472|     Bad|\n",
            "|   4085|Beverly Hills Cop...|3.5820329590199798|      13714|     Bad|\n",
            "|  45447|Da Vinci Code, Th...|3.1727983008419933|      13183|     Bad|\n",
            "|   6548|  Bad Boys II (2003)| 3.150354370570368|       5926|     Bad|\n",
            "|  38886|Squid and the Wha...|3.6726312201772324|       2934|     Bad|\n",
            "|    493|Menace II Society...| 3.618550213944123|       3973|     Bad|\n",
            "|   2076|  Blue Velvet (1986)|3.8593432496139153|      12303|     Bad|\n",
            "|   5390|           CQ (2001)|3.2462406015037595|        266|     Bad|\n",
            "+-------+--------------------+------------------+-----------+--------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Spark execution time: 0.05 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_stats.write.mode(\"overwrite\").csv(\"output/popular_movies_by_rating\", header=True)"
      ],
      "metadata": {
        "id": "QRdn-Wfn9cAY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONE SINGLE\n"
      ],
      "metadata": {
        "id": "vZzaHdOb9ok5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "start_time_join = time.time()\n",
        "ratings_pd = pd.read_csv(\"ratings.csv\")\n",
        "movies_pd = pd.read_csv(\"movies.csv\")\n",
        "\n",
        "data_pd = pd.merge(ratings_pd, movies_pd, on=\"movieId\")\n",
        "\n",
        "pandas_time_join = time.time() - start_time_join\n",
        "\n",
        "print(f\"Pandas join execution time: {pandas_time_join:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_Am283f9n__",
        "outputId": "1a844974-afd9-45d9-af49-f3668e3682d8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas join execution time: 22.39 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time2 = time.time()\n",
        "\n",
        "grouped = data_pd.groupby([\"movieId\", \"title\"])[\"rating\"].agg([\"mean\", \"count\"]).reset_index()\n",
        "grouped.columns = [\"movieId\", \"title\", \"avg_rating\", \"num_ratings\"]\n",
        "\n",
        "def classify(r):\n",
        "    if r >= 8:\n",
        "        return \"Excellent\"\n",
        "    elif r >= 7:\n",
        "        return \"Good\"\n",
        "    elif r >= 5:\n",
        "        return \"Regular\"\n",
        "    else:\n",
        "        return \"Bad\"\n",
        "\n",
        "grouped[\"category\"] = grouped[\"avg_rating\"].apply(classify)\n",
        "\n",
        "pandas_time2 = time.time() - start_time2\n",
        "\n",
        "print(grouped[[\"title\", \"avg_rating\", \"num_ratings\", \"category\"]].head(10))\n",
        "print(f\"Pandas execution time: {pandas_time2:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDcaW8ONDigM",
        "outputId": "03daf109-6301-4c3b-b7e7-85dc1849a76f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                title  avg_rating  num_ratings category\n",
            "0                    Toy Story (1995)    3.897438        68997      Bad\n",
            "1                      Jumanji (1995)    3.275758        28904      Bad\n",
            "2             Grumpier Old Men (1995)    3.139447        13134      Bad\n",
            "3            Waiting to Exhale (1995)    2.845331         2806      Bad\n",
            "4  Father of the Bride Part II (1995)    3.059602        13154      Bad\n",
            "5                         Heat (1995)    3.868277        29490      Bad\n",
            "6                      Sabrina (1995)    3.363968        13585      Bad\n",
            "7                 Tom and Huck (1995)    3.115563         1510      Bad\n",
            "8                 Sudden Death (1995)    2.987723         4154      Bad\n",
            "9                    GoldenEye (1995)    3.427850        32474      Bad\n",
            "Pandas execution time: 6.62 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison"
      ],
      "metadata": {
        "id": "di07oLY4DqXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Spark join execution time: {spark_time_join:.2f} seconds\")\n",
        "print(f\"Pandas join execution time: {pandas_time_join:.2f} seconds\")\n",
        "print(f\"Spark execution time: {spark_time:.2f} seconds\")\n",
        "print(f\"Pandas execution time: {pandas_time2:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrSMtszwDp7z",
        "outputId": "5bc69617-17e2-4101-99b3-0ae2a9773328"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark join execution time: 0.02 seconds\n",
            "Pandas join execution time: 22.39 seconds\n",
            "Spark execution time: 0.05 seconds\n",
            "Pandas execution time: 6.62 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CALCULATIONS ON TAGS\n"
      ],
      "metadata": {
        "id": "G9BWeddrCgJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spark"
      ],
      "metadata": {
        "id": "LuteztyCQcHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, length, when, explode, split\n",
        "import time\n",
        "\n",
        "spark = SparkSession.builder.appName(\"TagsWordLengthAnalysis\").getOrCreate()\n",
        "\n",
        "tags = spark.read.csv(\"tags.csv\", header=True, inferSchema=True)\n",
        "\n",
        "tags.show(5)"
      ],
      "metadata": {
        "id": "AcubjeytPNeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Explode: individual words\n",
        "words_df = tags.select(explode(split(col(\"tag\"), \"\\\\s+\")).alias(\"word\"))\n",
        "\n",
        "# 2. Add lenght column\n",
        "words_df = words_df.withColumn(\"length\", length(col(\"word\")))\n",
        "\n",
        "# 3. Clasification\n",
        "words_df = words_df.withColumn(\n",
        "    \"category\",\n",
        "    when(col(\"length\") == 1, \"Tiny\")\n",
        "    .when((col(\"length\") >= 2) & (col(\"length\") <= 4), \"Small\")\n",
        "    .when((col(\"length\") >= 5) & (col(\"length\") <= 9), \"Medium\")\n",
        "    .otherwise(\"Big\")\n",
        ")\n",
        "\n",
        "# 4. Count by category\n",
        "start = time.time()\n",
        "counts = words_df.groupBy(\"category\").count().orderBy(\"category\")\n",
        "counts.show()\n",
        "end = time.time()\n",
        "\n",
        "print(f\"Spark runtime: {end - start:.2f} seconds\")"
      ],
      "metadata": {
        "id": "KEWCJ6sIPyPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas"
      ],
      "metadata": {
        "id": "oVyXz0H6QZ4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "tags_pd = pd.read_csv(\"tags.csv\")\n",
        "all_words = tags_pd['tag'].str.split()\n",
        "\n",
        "words_list = [word for sublist in all_words for word in sublist]\n",
        "\n",
        "def classify_word(word):\n",
        "    l = len(word)\n",
        "    if l == 1:\n",
        "        return \"Tiny\"\n",
        "    elif 2 <= l <= 4:\n",
        "        return \"Small\"\n",
        "    elif 5 <= l <= 9:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Big\"\n",
        "\n",
        "start = time.time()\n",
        "categories = [classify_word(w) for w in words_list]\n",
        "counts_pd = pd.Series(categories).value_counts().sort_index()\n",
        "end = time.time()\n",
        "\n",
        "print(counts_pd)\n",
        "print(f\"Pandas runtime: {end - start:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "xSeYL-K6QUnf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
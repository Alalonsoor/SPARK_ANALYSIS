{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "HOMEWORK 6 - Movie Rating Analysis using Apache Spark (Pipeline)"
      ],
      "metadata": {
        "id": "utsWCrAk_r_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing Space"
      ],
      "metadata": {
        "id": "Y0nuDnlk9zmC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "q6lhYyXl_l8S",
        "outputId": "87e3b326-5d4c-4113-d902-66775fa2b874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to r2u.stat.illinois.\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 257 kB in 1s (218 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "movies.csv   sample_data\t\t    spark-3.1.1-bin-hadoop3.2.tgz.1\n",
            "output\t     spark-3.1.1-bin-hadoop3.2\t    tags.csv\n",
            "ratings.csv  spark-3.1.1-bin-hadoop3.2.tgz\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78e442dec590>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a41cf1da449f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>MovieRatingsAnalysis</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Install and configure Spark environment\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "\n",
        "!ls\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload datasets ratings and movies from the 32M dataset"
      ],
      "metadata": {
        "id": "AadqKrL799_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"MovieRatingsAnalysis\").getOrCreate()\n",
        "\n",
        "movies = spark.read.csv(\"movies.csv\", header=True, inferSchema=True)\n",
        "ratings = spark.read.csv(\"ratings.csv\", header=True, inferSchema=True)\n",
        "\n",
        "start_time_join = time.time()\n",
        "data = ratings.join(movies, on=\"movieId\")\n",
        "spark_time_join = time.time() - start_time_join\n",
        "\n",
        "print(f\"Spark join execution time: {spark_time_join:.2f} seconds\")\n",
        "\n",
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MfuUfEE88xY",
        "outputId": "83483c3e-46d9-4f20-abeb-d4fe94d9dfa8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark join execution time: 0.01 seconds\n",
            "+-------+------+------+---------+--------------------+--------------------+\n",
            "|movieId|userId|rating|timestamp|               title|              genres|\n",
            "+-------+------+------+---------+--------------------+--------------------+\n",
            "|     17|     1|   4.0|944249077|Sense and Sensibi...|       Drama|Romance|\n",
            "|     25|     1|   1.0|944250228|Leaving Las Vegas...|       Drama|Romance|\n",
            "|     29|     1|   2.0|943230976|City of Lost Chil...|Adventure|Drama|F...|\n",
            "|     30|     1|   5.0|944249077|Shanghai Triad (Y...|         Crime|Drama|\n",
            "|     32|     1|   5.0|943228858|Twelve Monkeys (a...|Mystery|Sci-Fi|Th...|\n",
            "+-------+------+------+---------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we would do is calculate average rating and number of ratings for each movie, and then classify it between different categories"
      ],
      "metadata": {
        "id": "qfAZ26v1_DX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import avg, count, when\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "movie_stats = data.groupBy(\"movieId\", \"title\") \\\n",
        "    .agg(avg(\"rating\").alias(\"avg_rating\"), count(\"rating\").alias(\"num_ratings\"))\n",
        "\n",
        "movie_stats = movie_stats.withColumn(\n",
        "    \"category\",\n",
        "    when(movie_stats.avg_rating >= 8, \"Excellent\")\n",
        "    .when(movie_stats.avg_rating >= 7, \"Good\")\n",
        "    .when(movie_stats.avg_rating >= 5, \"Regular\")\n",
        "    .otherwise(\"Bad\")\n",
        ")\n",
        "\n",
        "category_counts = movie_stats.groupBy(\"category\").agg(count(\"*\").alias(\"total_movies\"))\n",
        "category_counts.show()\n",
        "\n",
        "spark_time = time.time() - start_time\n",
        "\n",
        "movie_stats.show(10)\n",
        "print(f\"Spark execution time: {spark_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_yn7onX9VMz",
        "outputId": "7eb2916f-921a-4361-f90d-8ad82834b364"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------+\n",
            "|category|total_movies|\n",
            "+--------+------------+\n",
            "|     Bad|       82987|\n",
            "| Regular|        1445|\n",
            "+--------+------------+\n",
            "\n",
            "+-------+--------------------+------------------+-----------+--------+\n",
            "|movieId|               title|        avg_rating|num_ratings|category|\n",
            "+-------+--------------------+------------------+-----------+--------+\n",
            "|    442|Demolition Man (1...|3.0941247002398082|      20850|     Bad|\n",
            "| 183837|       The Favourite|3.8472875509564126|       3189|     Bad|\n",
            "|   2657|Rocky Horror Pict...| 3.363947776628749|      15472|     Bad|\n",
            "|   4085|Beverly Hills Cop...|3.5820329590199798|      13714|     Bad|\n",
            "|  45447|Da Vinci Code, Th...|3.1727983008419933|      13183|     Bad|\n",
            "|   6548|  Bad Boys II (2003)| 3.150354370570368|       5926|     Bad|\n",
            "|  38886|Squid and the Wha...|3.6726312201772324|       2934|     Bad|\n",
            "|    493|Menace II Society...| 3.618550213944123|       3973|     Bad|\n",
            "|   2076|  Blue Velvet (1986)|3.8593432496139153|      12303|     Bad|\n",
            "|   5390|           CQ (2001)|3.2462406015037595|        266|     Bad|\n",
            "+-------+--------------------+------------------+-----------+--------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Spark execution time: 62.17 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_stats.write.mode(\"overwrite\").csv(\"output/popular_movies_by_rating\", header=True)"
      ],
      "metadata": {
        "id": "QRdn-Wfn9cAY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONE SINGLE\n"
      ],
      "metadata": {
        "id": "vZzaHdOb9ok5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "start_time_join = time.time()\n",
        "ratings_pd = pd.read_csv(\"ratings.csv\")\n",
        "movies_pd = pd.read_csv(\"movies.csv\")\n",
        "\n",
        "data_pd = pd.merge(ratings_pd, movies_pd, on=\"movieId\")\n",
        "\n",
        "pandas_time_join = time.time() - start_time_join\n",
        "\n",
        "print(f\"Pandas join execution time: {pandas_time_join:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_Am283f9n__",
        "outputId": "c4393245-9319-43fb-ea3a-c1b6eda862e5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas join execution time: 33.18 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time2 = time.time()\n",
        "\n",
        "grouped = data_pd.groupby([\"movieId\", \"title\"])[\"rating\"].agg([\"mean\", \"count\"]).reset_index()\n",
        "grouped.columns = [\"movieId\", \"title\", \"avg_rating\", \"num_ratings\"]\n",
        "\n",
        "def classify(r):\n",
        "    if r >= 8:\n",
        "        return \"Excellent\"\n",
        "    elif r >= 7:\n",
        "        return \"Good\"\n",
        "    elif r >= 5:\n",
        "        return \"Regular\"\n",
        "    else:\n",
        "        return \"Bad\"\n",
        "\n",
        "grouped[\"category\"] = grouped[\"avg_rating\"].apply(classify)\n",
        "\n",
        "category_counts_pd = grouped[\"category\"].value_counts().sort_index()\n",
        "print(category_counts_pd)\n",
        "\n",
        "pandas_time2 = time.time() - start_time2\n",
        "\n",
        "print(grouped[[\"title\", \"avg_rating\", \"num_ratings\", \"category\"]].head(10))\n",
        "print(f\"Pandas execution time: {pandas_time2:.2f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDcaW8ONDigM",
        "outputId": "a7caf773-0e9e-4008-b9be-19c13eec7132"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "category\n",
            "Bad        82987\n",
            "Regular     1445\n",
            "Name: count, dtype: int64\n",
            "                                title  avg_rating  num_ratings category\n",
            "0                    Toy Story (1995)    3.897438        68997      Bad\n",
            "1                      Jumanji (1995)    3.275758        28904      Bad\n",
            "2             Grumpier Old Men (1995)    3.139447        13134      Bad\n",
            "3            Waiting to Exhale (1995)    2.845331         2806      Bad\n",
            "4  Father of the Bride Part II (1995)    3.059602        13154      Bad\n",
            "5                         Heat (1995)    3.868277        29490      Bad\n",
            "6                      Sabrina (1995)    3.363968        13585      Bad\n",
            "7                 Tom and Huck (1995)    3.115563         1510      Bad\n",
            "8                 Sudden Death (1995)    2.987723         4154      Bad\n",
            "9                    GoldenEye (1995)    3.427850        32474      Bad\n",
            "Pandas execution time: 9.93 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison"
      ],
      "metadata": {
        "id": "di07oLY4DqXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Spark join execution time: {spark_time_join:.2f} seconds\")\n",
        "print(f\"Pandas join execution time: {pandas_time_join:.2f} seconds\")\n",
        "print(f\"Spark execution time: {spark_time:.2f} seconds\")\n",
        "print(f\"Pandas execution time: {pandas_time2:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrSMtszwDp7z",
        "outputId": "ab736939-4715-468b-e80e-da8d78a3d5f8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark join execution time: 0.01 seconds\n",
            "Pandas join execution time: 33.18 seconds\n",
            "Spark execution time: 62.17 seconds\n",
            "Pandas execution time: 9.93 seconds\n"
          ]
        }
      ]
    }
  ]
}